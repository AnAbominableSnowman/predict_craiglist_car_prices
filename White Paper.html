<!DOCTYPE html><html><head>
      <title>White Paper</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\17152\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.14\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h2 id="marketing-tracking-of-craiglists-used-cars">Marketing Tracking of Craiglist's Used Cars </h2>
<h2 id="table-of-contents">Table of Contents </h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#problem-definition">Problem Definition</a></li>
<li><a href="#data-collection">Data Collection</a></li>
<li><a href="#exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</a></li>
<li><a href="#data-preprocessing">Data Preprocessing</a></li>
<li><a href="#feature-engineering">Feature Engineering</a></li>
<li><a href="#modeling">Modeling</a></li>
<li><a href="#model-evaluation">Model Evaluation</a></li>
<li><a href="#conclusion-and-future-work">Conclusion and Future Work</a></li>
<li><a href="#references">References</a></li>
</ol>
<h2 id="introduction">Introduction </h2>
<p><strong>Growing up, I had a family friend who was always poring over Craigslist ads, buying cars, fixing them up, and flipping them for profit. Each flip took him at least forty hours of searching. I can still picture him, bathed in the dim glow of a cathode ray tube, surrounded by stacks of booklets.</strong></p>
<p>This project is an ode to that family friend. It aims to build a tool to predict Craigslist car prices—similar to the tools used by Kelley Blue Book and captive financial companies like Ford Financing. Our anonymous hero could use this tool to efficiently find underpriced offers and snatch them up before others do.</p>
<p>Taking it a step further, our hero could even create a synthetic dataset of a thousand representative vehicles, train the model month by month, and observe how the prices of your synthetic vehicles change over time. Knowing the test data was fixed, any changes in price are attributable to changes in the trained model. This could be used as an index providing valuable insights into market trends and movements.</p>
<h2 id="problem-definition">Problem Definition </h2>
<p>A generous contributor has scraped 450,000 car postings from Craigslist and shared them on <a href="https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data/code">Kaggle</a>. I have downloaded the zipped CSV file, and this is where our analysis begins. The target variable is the price, represented in USD. The dataset includes eighteen useful covariates, such as a region, a metro area, price in USD, year, year of manufacture, manufacturer (e.g., Ram or Jeep), model (e.g., Silverado or Forester), condition (e.g., good or fair), cylinders (e.g., 4 or 6), fuel (e.g., diesel or gas), odometer (miles traveled), title status (e.g., rebuilt or clean), transmission (e.g., automatic or manual), drive (e.g., FWD or RWD), type (e.g., sedan or truck), paint color (e.g., white or black), state (e.g., Wisconsin), and lat(itude) and long(itude) (representing geographical location).</p>
<h2 id="exploratory-data-analysis-eda">Exploratory Data Analysis (EDA) </h2>
<h3 id="1-data-overview">1. Data Overview </h3>
<p>For a thorough EDA using <code>y_data_profiling</code>, see the visualizations from <a href="results/data_profile_cleaned_subsampled_to_one_percent">pre_proccessing</a> and <a href="results/data_profile_raw_subsampled_to_one_percent">post processing</a>. In the interest of space, I will mention the most pertinent details. The price variable is heavily right-skewed, as is the odometer reading, which contains some incredible values of 10 million or more—equivalent to twenty round trips to the moon. It’s safe to say there are some data quality issues, which we will address in <a href="#data-preprocessing">data preprocessing</a>. Another pertinent topic is the high frequency of Carvana ads at XYZ%; since they exhibit higher data quality and more consistency across ads, they form an interesting part of the puzzle. However, their descriptions are mostly identicial boilerplate across many ads.</p>
<p>Digging into correlations below, we see a three-way interaction among price, age, and odometer reading. Older vehicles typically have more miles and are worth less; untangling mileage from age is a complex problem that is be beyond the scope of this paper. We also notice interactions between (word frequnecy)[#feature-engineering] and odometer readings, suggesting that certain words are used more or less frequently depending on car mileage; this aligns with expectations. No one describes their brand new sports car as "reliable"; that term of endearment is typically reserved for the family workhorse van that has been picking up groceries for a decade or more. Note, for brevity, tf_idf words and correlations aren't in the paper but can be found <a href="results">here</a></p>
<p>Finally, the manufacturer shows a correlation with both the number of cylinders and transmission type, which again conforms to common sense. Additionally, about eleven percent of the rows appear to be exact duplicates. While they could represent truly different cars, the exact matching of price, odometer, color, etc., strains credibility, so we will drop these results. Likely people are reposting the same ad to make their ad appear new.</p>
<div style="display: flex; gap: 40px;">
    <img src="results/Simple Linear Regression of Price by Odometer/corrgram_clean.png" alt="Image 1">
    <!-- <img src="results/Simple Linear Regression of Price by Odometer/ols_results.png" alt="Image 2"> -->
</div>
<h3 id="2-data-visualization">2. Data Visualization </h3>
<ul>
<li>Histograms of numerical features (e.g., price distribution)</li>
<li>Scatter plots (e.g., price vs. mileage, price vs. year)</li>
<li>Correlation heatmaps to show relationships between features</li>
</ul>
<h2 id="data-preprocessing-and-feature-engineering">Data Preprocessing and Feature Engineering </h2>
<h3 id="1-handling-missing-values">1. Handling Missing Values </h3>
<p>Missing price or odometer readings were removed, as they are too crucial to attempt imputation. Missing values were only imputed for the linear regression approach, using a standard mean or mode method. A brief examination of missing values is in order. All columns likely exhibit a mix of Missing Not at Random (MNAR) and Missing at Random (MAR). Missing descriptions are probably absent because it’s difficult to provide a good description for a poorly maintained car. Conversely, a rusted, sun-beaten car missing a paint color is missing at random, as the absence is tied to the condition of the car rather than the paint color itself. This type of missingness should cast some doubt on any results derived from the linear regression analysis. Being more frank, any analysis should be somewhat questioned with data accidentally, intentionally and perhaps maliciously missing.</p>
<h3 id="2-filtering-data">2 Filtering Data </h3>
<p>Craigslist seems especially prone to messy data for two reasons: individual posters are not professionals with a corporate image, and hiding information is generally advantageous—most importantly, due to price anchoring. Good cars that are worth a lot are typically owned by more internet-savvy individuals, who understand that spending time to create a great ad to gain even a 2% increase in price is worth it for a more expensive car. Conversely, the negative aspects of a car are often best left unmentioned and discussed later if inquiries arise.</p>
<p>The other key problem is <a href="https://en.wikipedia.org/wiki/Anchoring_effect">price anchoring</a>. The highest price a seller will get for their car is often determined by the first price they mention. It's much better to allow the buyer to propose a price and then ask for more. By not listing a price or by listing unrealistic values like <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><mi>m</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>o</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">9 million or</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">9</span><span class="mord mathnormal">mi</span><span class="mord mathnormal" style="margin-right:0.01968em;">ll</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span></span></span></span>1, sellers can avoid anchoring their price.</p>
<p>With this in mind, I applied several filters to the dataset. I removed any cars priced under <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo separator="true">,</mo><mn>000</mn><mo separator="true">,</mo><mi>a</mi><mi>s</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>e</mi><mi>e</mi><mi>i</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>r</mi><mi>s</mi><mi>c</mi><mi>r</mi><mi>a</mi><mi>p</mi><mi mathvariant="normal">/</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>s</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>e</mi><mi>x</mi><mi>a</mi><mi>m</mi><mi>p</mi><mi>l</mi><mi>e</mi><mi>s</mi><mi>o</mi><mi>f</mi><mi>p</mi><mi>r</mi><mi>i</mi><mi>c</mi><mi>e</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mo separator="true">,</mo><mi>a</mi><mi>n</mi><mi>d</mi><mi>e</mi><mi>x</mi><mi>c</mi><mi>l</mi><mi>u</mi><mi>d</mi><mi>e</mi><mi>d</mi><mi>a</mi><mi>n</mi><mi>y</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>s</mi><mi>p</mi><mi>r</mi><mi>i</mi><mi>c</mi><mi>e</mi><mi>d</mi><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">2,000, as these were either scrap/parts cars or examples of price anchoring, and excluded any cars priced over</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">000</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">ese</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">eree</span><span class="mord mathnormal">i</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02778em;">erscr</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord">/</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">sc</span><span class="mord mathnormal">a</span><span class="mord mathnormal">rsore</span><span class="mord mathnormal">x</span><span class="mord mathnormal">am</span><span class="mord mathnormal" style="margin-right:0.01968em;">pl</span><span class="mord mathnormal">eso</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ce</span><span class="mord mathnormal">an</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">an</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">x</span><span class="mord mathnormal">c</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">u</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">d</span><span class="mord mathnormal">an</span><span class="mord mathnormal">yc</span><span class="mord mathnormal">a</span><span class="mord mathnormal">rs</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ce</span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span></span></span></span>125,000. Most of the ads I found above $125,000 appeared illegitimate. Additionally, I removed any cars with over 300,000 miles, as this is a reasonable upper limit for a car's lifespan; most of these were likely examples obfuscating obscure poor condition. Lastly, I removed all duplicate rows, which eliminated about eleven percent of the data; this is do to people reposting ads to appear new and garner more clicks.</p>
<h3 id="2-feature-engineering">2. Feature Engineering </h3>
<p>This process primarily consisted of two parts. The first part involved standard feature engineering. I created flags to indicate whether the ad included a description and whether it was a Carvana ad. Additionally, I converted the condition from a categorical to an ordinal variable. The categories "Excellent," "Fair," and "Poor" have a clear order, and this information should be retained. Similarly, I converted the number of cylinders from a string to a numeric type to preserve that ordinal information but this created a column of mixed types that polars would infrequently fail on; so this code has been removed and <a href="https://github.com/AnAbominableSnowman/video_game_sales_predictions/issues/17">an issue</a> created to one day replace it.</p>
<p>The more interesting piece of feature engineering involved analyzing the description text. Much of the text analysis centers on classification and sentiment analysis. My initial approach was a bag-of-words style method, but I pivoted to<a href="https://builtin.com/articles/tf-idf">term frequency, inverse document frequency</a>. In short, words that appear in fewer descriptions are weighted more heavily (IDF), while words that appear frequently in a specific document are also weighted more heavily (TF). Ultimately, this results in a column of words along with their scores for each individual row (i.e., description). We can then use these as variables in our modeling later on.</p>
<h2 id="modeling">Modeling </h2>
<table>
<thead>
<tr>
<th>Model</th>
<th>Explanatory Variables</th>
<th>Hyper Parameters</th>
<th>RMSE</th>
<th>R²</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ordinary Least Squares</td>
<td>odometer</td>
<td><code>None</code></td>
<td>$12110</td>
<td>29.2%</td>
</tr>
<tr>
<td>Log Least Squares</td>
<td>year, manufacturer, odometer, paint_color, state, title_status</td>
<td><code>None</code></td>
<td>$10,986</td>
<td>41.8%</td>
</tr>
<tr>
<td>LightGBM</td>
<td>all standard variables</td>
<td><code>{'learning_rate': 0.01, 'max_depth': 6,'boosting_type': "gbdt"</code></td>
<td>$6180</td>
<td>81.7%</td>
</tr>
<tr>
<td>LightGBM with HyperOpt and Text</td>
<td>all standard variables, has_description?, is_carvana_ad?, 500 words (TF_IDF)</td>
<td><code>{'learning_rate': 0.05, 'max_depth': 8,'boosting_type': "gbdt",'number_of_leaves':166,'min_data_in_leaf': 5000}</code></td>
<td>$4998</td>
<td>88%</td>
</tr>
</tbody>
</table>
<p><em>Table 1</em> The four modeling approaches</p>
<h3 id="1-simple-ordinary-least-squares">1. Simple Ordinary Least Squares </h3>
<p>I iterated through four models in this project, progressively improving with each iteration. To assess model quality, I will use RMSE and R² while also favoring simpler models with equivalent success. My first model was the starting point for almost any good regression data science project: linear regression. My baseline was ordinary least squares regression with the odometer as my covariate.</p>
<p>The good news is that this model trains incredibly quickly and is the most interpretable of all models. I obtained a final RMSE of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mo separator="true">,</mo><mn>000</mn><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>n</mi><msup><mi>R</mi><mn>2</mn></msup><mi>o</mi><mi>f</mi><mn>29</mn></mrow><annotation encoding="application/x-tex">12,000 and an R² of 29%. This means the model is off by about</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em;"></span><span class="mord">12</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">000</span><span class="mord mathnormal">an</span><span class="mord mathnormal">d</span><span class="mord mathnormal">an</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord">29</span></span></span></span>12,000 on average, which isn't good enough for our use case. While the odometer explains about 29% of the total variation in price, the model's extreme interpretability is also a plus: any car's value starts at $31,140, and each consecutive mile reduces its value by 12.75 cents.</p>
<p>In the interest of brevity, I won't delve too deeply into checking the assumptions, as they all fail: linearity, homoscedasticity, and normality. While many types of inference are robust, this is too much for even the most robust linear regression inferences. Left with an uninterpretable and inaccurate model, it's time to go back to the drawing board. Another issue is the negative predictions; after 250,000 miles, the model starts predicting negative prices.</p>
<div style="display: flex; gap: 40px;">
    <img src="results/Simple Linear Regression of Price by Odometer/residuals.png" alt="Image 1">
    <img src="results/Simple Linear Regression of Price by Odometer/ols_results.png" alt="Image 2">
</div>
_*Figure 1*_ Results of the simple least squares regression, note how many predictions are actually negative.  
<h3 id="2-log-multiple-least-squares">2. Log Multiple Least Squares </h3>
<p>In my next model, I aimed to tackle two issues: many negative price predictions and a reduction in bias at the cost of increased variance. To address the first problem, I started by logging the price. The intuition behind this approach is that price spans several magnitudes, and predicting the logarithm will never yield negative values.</p>
<p>The second strategy for addressing an underfitting model involved introducing additional terms: year, manufacturer, state, title status, and paint color. I selected these variables because they exhibit low cardinality, align with lived experience and common sense, and have low rates of missing values. Variables with a significant number of missing values would require extensive mean/mode imputation, which could diminish their value. Additionally, variables with high cardinality reduce model interpretability and risk fragmenting the data too thinly.</p>
<p>Reviewing the results below, the negative predictions have disappeared, and we observe an improvement in model accuracy, with approximately 40% of the variability in price explained by our model. Furthermore, we are now, on average, off by about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo separator="true">,</mo><mn>000</mn><mi>l</mi><mi>e</mi><mi>s</mi><mi>s</mi><mo separator="true">,</mo><mi>b</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>R</mi><mi>M</mi><mi>S</mi><mi>E</mi><mi>d</mi><mi>o</mi><mi>w</mi><mi>n</mi><mi>t</mi><mi>o</mi></mrow><annotation encoding="application/x-tex">1,000 less, bringing the RMSE down to</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord">000</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">ess</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em;"></span><span class="mord mathnormal">b</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.05764em;">RMSE</span><span class="mord mathnormal">d</span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal">n</span><span class="mord mathnormal">t</span><span class="mord mathnormal">o</span></span></span></span>11,000. While this is a great step toward accuracy, we now have 80 separate terms in the function. Additionally, we have correlated covariates skewing our beta coefficients, leading to peculiar results, such as cars in West Virginia being more expensive than those in New York.</p>
<div style="display: flex; gap: 40px;">
    <img src="results/Log price Linear Regression/residuals.png" alt="Image 1">
    <img src="results/Log price Linear Regression/Log_mls_results.png" alt="Image 2">
</div>
_*Figure 12*_ Results of the log mulitiple least squares regression, note I cut off many rows in the results for brevity. Full results can be found in GH. 
<h3 id="3light-gbm">3.Light GBM </h3>
<p>Linear regression isn’t going to cut it on this dataset, so I'll try another tool: LightGBM. Let's begin with a naive approach, using all of our usable variables while leaving out any words, feature-engineered variables, or hyperparameter tuning. Consider this more of a baseline approach.</p>
<p>The great news is that this method provided a dramatic improvement in our model's performance. Our RMSE dropped down to $6,200, and our model can explain about 82% of the variation in price. This is a significant improvement in accuracy, but it did cost us a bit in terms of speed and explainability. Specifically, the time to fit the model increased from about 10 seconds for the previous model to around four minutes for this one. Given that this is a model that would likely be trained once a week at most, this trade-off is acceptable to me.</p>
<p>Addressing interpretability is a bit more challenging, but I will use <a href="https://shap.readthedocs.io/en/latest/index.html">SHAP</a> to better understand how specific variables affect the predictions. The SHAP summary plot below can seem daunting at first. However, if we look at the first row, "year," we see that the farther right you go, the higher the SHAP value, which increases the predicted price. Most of the rightmost values are red, indicating high feature values, which aligns with our expectation: newer manufacturing years are likely to sell for more.</p>
<p>Odometer has a similar but opposite story for obvious reasons, more mileage, cheaper car. Interestingly, longitude, at the lowest values (light blue), is associated with positive increases in price (high SHAP values). This could be explained by the fact that the west coast and Hawaii—locations with lower longitude—are high-cost-of-living areas. An alternate explanation might be warmer climates out west use less salt in winter and therefore less rust perhaps.</p>
<p>Categorical variables are a bit harder to use in SHAP summary plots as they lack the clear sense of bigger to smaller and the resulting colorings. However, some categorical variables do tell a story. The far-right skew in the region seems to suggest region usually doesn't tell affect price much, but it has occasionally driven price up substanially. I haven't figured out how to pinpoint what values these are yet but  I suspect they correspond to these high-cost locations. Similarly, title status mostly has no effect on value, but certain titles can severely decrease the price. This aligns with our EDA, where most titles were clean, while some were salvage, parts, or lien, all of which can hinder a high sale price.</p>
<div style="display: flex; gap: 40px;">
    <img src="results\light_gbm_basic/shap_summary_plot.png" alt="Image 1">
    <img src="results\light_gbm_basic\rmse_over_rounds.png" alt="Image 2">
</div>
<h3 id="4-light-gbm-with-hyperopt-and-words">4. Light GBM with HyperOpt and Words </h3>
<p>From here, there is a kaledoscope of options to try next: hyper parameter tuning, add it text data from the description, utilize lat and long to pull in zip code data, implementing crossvalidation, explore the time and date of posting.</p>
<p>The first stop was addressing overfit and while here, I might as well set up HyperOpt. HyperOpt is one of my favorite tools for hyperparameter optimization. It uses a Bayesian framework to more efficeintly search using prior runs to inform future runs. An analogy, You are looking for a plane that flew between New York and London and crashed in the ocean. If you find debries, you should bring all your searchers in to that one spot and really comb that location.</p>
<p>There are three main hyperparemeters I tried to optimize; learning rate, max depth, number of TF_IDF words and L1, L2 regularization. We are not tuning on number of leaves.I have fixed that to be 65% of 2^max_depth. <a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html">Why?</a>. Because Light GBM grows leaf first, not level first. By fitting max depth and setting leaves to be equal to it, you just back yourself in a level first methodology ala random forest. This is okay if you don't have over fit, but we do, so were doing it like this instead.</p>
<p>Number of TF_IDF was always selected to be max at 500, so the existing code doesn't show this as checking this was wasting compute. Trying both L1 and L2 regualarization at the same time is inspired by ElasticNet; this idea was inspired by <a href="https://datascience.stackexchange.com/questions/57255/l1-l2-regularization-in-light-gbm">StackExchange</a>.</p>
<p>Interpting TF_IDF, TO DO DEVIN</p>
<div style="display: flex; gap: 40px;">
    <img src="results/light_gbm__hyperopt_and_feature_engineering/shap_summary_plot.png" alt="Image 1">
    <img src="results\light_gbm__HyperOpt_and_feature_engineering\rmse_over_rounds.png" alt="Image 2">
</div>
<p>FIX UP ALT image titles</p>
<h3 id="compare-the-given-models">Compare the given models. </h3>
<p>Comparing the models, Linear regression should offer interptability and statistical infrence. But without any of the assumptions holding and high correlation, that doesn't really hold. As such, I think Light GBM is just a better model for this use case. The next questions becomes, do you want to use the model with TF_IDF and feature engineering or the base model. The more complex model, four, is about five times slower to train. But in my envisioned use case, it only trains at most once a week. So model training speed isn't super important. Prediction speed is perhaps a bit more important as you want to be scraping data, and predicting on the data daily if not hourly so you can know about the deals asap!</p>
<p>I think the ideal end case is using model four and using a model in combination with SHAP to create a waterfall plot and see how and why the lightGBM model is adjusting the price how it is. From there, you can use subject matter expertise, to agree with, tweak or ignore each prediction. Heres an example from the model we trained.  TO DO DEVIN FILL IN T</p>
<h2 id="conclusion-and-future-work">Conclusion and Future Work </h2>
<p>In conclusion, we found a featured engineered model with text in Light GBM to be the best model. We were able to get an RMSE OF XYZ and epxlaine about UFUF% of the variance in price. The most important variables were odometer, region and year along with word XSSS,SSSD,KKKD,DDDD, TO DO DEVIN. THis current approach has limitiations, it is limited to the time frame the data was scraped (early 2024) and we cut about 15% of the totals rows due to impossible odometers and prices. These were corrupt at random and its hard to say how this changes the model and our depiction of it. Finally, Carvana is a bit player in the market, but given how fractured the craigslist market it, they are by far the ]biggest player. They very well might set the market and more fcuse should be given to their pricign.</p>
<h2 id="future-work">Future work </h2>
<p>Pull out useful info from  craigslist carvana ad's. Today there is too much static data in the descriptions that overwhelems TF_IDF, so I turn carvana ad's into a boolean varialbe. A further analysis could just delete the boiler plate and extract the nuggets.</p>
<p>Find and utilzie the images. The current data only points to image URLs; I could go an download all these images and then utilize them. Thats beyond the scope of this project today. But from here, you could build a CVML model to detect car quality. Specifically looking for things like rust, dents, and scratches. I know this is possible and have worekd on it before but can't share more without spilling the secret sauce.</p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>