<!DOCTYPE html><html><head>
      <title>White Paper</title>
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width, initial-scale=1.0">
      
      <link rel="stylesheet" href="file:///c:\Users\17152\.vscode\extensions\shd101wyy.markdown-preview-enhanced-0.8.14\crossnote\dependencies\katex\katex.min.css">
      
      
      
      
      
      <style>
      code[class*=language-],pre[class*=language-]{color:#333;background:0 0;font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;line-height:1.4;-moz-tab-size:8;-o-tab-size:8;tab-size:8;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}pre[class*=language-]{padding:.8em;overflow:auto;border-radius:3px;background:#f5f5f5}:not(pre)>code[class*=language-]{padding:.1em;border-radius:.3em;white-space:normal;background:#f5f5f5}.token.blockquote,.token.comment{color:#969896}.token.cdata{color:#183691}.token.doctype,.token.macro.property,.token.punctuation,.token.variable{color:#333}.token.builtin,.token.important,.token.keyword,.token.operator,.token.rule{color:#a71d5d}.token.attr-value,.token.regex,.token.string,.token.url{color:#183691}.token.atrule,.token.boolean,.token.code,.token.command,.token.constant,.token.entity,.token.number,.token.property,.token.symbol{color:#0086b3}.token.prolog,.token.selector,.token.tag{color:#63a35c}.token.attr-name,.token.class,.token.class-name,.token.function,.token.id,.token.namespace,.token.pseudo-class,.token.pseudo-element,.token.url-reference .token.variable{color:#795da3}.token.entity{cursor:help}.token.title,.token.title .token.punctuation{font-weight:700;color:#1d3e81}.token.list{color:#ed6a43}.token.inserted{background-color:#eaffea;color:#55a532}.token.deleted{background-color:#ffecec;color:#bd2c00}.token.bold{font-weight:700}.token.italic{font-style:italic}.language-json .token.property{color:#183691}.language-markup .token.tag .token.punctuation{color:#333}.language-css .token.function,code.language-css{color:#0086b3}.language-yaml .token.atrule{color:#63a35c}code.language-yaml{color:#183691}.language-ruby .token.function{color:#333}.language-markdown .token.url{color:#795da3}.language-makefile .token.symbol{color:#795da3}.language-makefile .token.variable{color:#183691}.language-makefile .token.builtin{color:#0086b3}.language-bash .token.keyword{color:#0086b3}pre[data-line]{position:relative;padding:1em 0 1em 3em}pre[data-line] .line-highlight-wrapper{position:absolute;top:0;left:0;background-color:transparent;display:block;width:100%}pre[data-line] .line-highlight{position:absolute;left:0;right:0;padding:inherit 0;margin-top:1em;background:hsla(24,20%,50%,.08);background:linear-gradient(to right,hsla(24,20%,50%,.1) 70%,hsla(24,20%,50%,0));pointer-events:none;line-height:inherit;white-space:pre}pre[data-line] .line-highlight:before,pre[data-line] .line-highlight[data-end]:after{content:attr(data-start);position:absolute;top:.4em;left:.6em;min-width:1em;padding:0 .5em;background-color:hsla(24,20%,50%,.4);color:#f4f1ef;font:bold 65%/1.5 sans-serif;text-align:center;vertical-align:.3em;border-radius:999px;text-shadow:none;box-shadow:0 1px #fff}pre[data-line] .line-highlight[data-end]:after{content:attr(data-end);top:auto;bottom:.4em}html body{font-family:'Helvetica Neue',Helvetica,'Segoe UI',Arial,freesans,sans-serif;font-size:16px;line-height:1.6;color:#333;background-color:#fff;overflow:initial;box-sizing:border-box;word-wrap:break-word}html body>:first-child{margin-top:0}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{line-height:1.2;margin-top:1em;margin-bottom:16px;color:#000}html body h1{font-size:2.25em;font-weight:300;padding-bottom:.3em}html body h2{font-size:1.75em;font-weight:400;padding-bottom:.3em}html body h3{font-size:1.5em;font-weight:500}html body h4{font-size:1.25em;font-weight:600}html body h5{font-size:1.1em;font-weight:600}html body h6{font-size:1em;font-weight:600}html body h1,html body h2,html body h3,html body h4,html body h5{font-weight:600}html body h5{font-size:1em}html body h6{color:#5c5c5c}html body strong{color:#000}html body del{color:#5c5c5c}html body a:not([href]){color:inherit;text-decoration:none}html body a{color:#08c;text-decoration:none}html body a:hover{color:#00a3f5;text-decoration:none}html body img{max-width:100%}html body>p{margin-top:0;margin-bottom:16px;word-wrap:break-word}html body>ol,html body>ul{margin-bottom:16px}html body ol,html body ul{padding-left:2em}html body ol.no-list,html body ul.no-list{padding:0;list-style-type:none}html body ol ol,html body ol ul,html body ul ol,html body ul ul{margin-top:0;margin-bottom:0}html body li{margin-bottom:0}html body li.task-list-item{list-style:none}html body li>p{margin-top:0;margin-bottom:0}html body .task-list-item-checkbox{margin:0 .2em .25em -1.8em;vertical-align:middle}html body .task-list-item-checkbox:hover{cursor:pointer}html body blockquote{margin:16px 0;font-size:inherit;padding:0 15px;color:#5c5c5c;background-color:#f0f0f0;border-left:4px solid #d6d6d6}html body blockquote>:first-child{margin-top:0}html body blockquote>:last-child{margin-bottom:0}html body hr{height:4px;margin:32px 0;background-color:#d6d6d6;border:0 none}html body table{margin:10px 0 15px 0;border-collapse:collapse;border-spacing:0;display:block;width:100%;overflow:auto;word-break:normal;word-break:keep-all}html body table th{font-weight:700;color:#000}html body table td,html body table th{border:1px solid #d6d6d6;padding:6px 13px}html body dl{padding:0}html body dl dt{padding:0;margin-top:16px;font-size:1em;font-style:italic;font-weight:700}html body dl dd{padding:0 16px;margin-bottom:16px}html body code{font-family:Menlo,Monaco,Consolas,'Courier New',monospace;font-size:.85em;color:#000;background-color:#f0f0f0;border-radius:3px;padding:.2em 0}html body code::after,html body code::before{letter-spacing:-.2em;content:'\00a0'}html body pre>code{padding:0;margin:0;word-break:normal;white-space:pre;background:0 0;border:0}html body .highlight{margin-bottom:16px}html body .highlight pre,html body pre{padding:1em;overflow:auto;line-height:1.45;border:#d6d6d6;border-radius:3px}html body .highlight pre{margin-bottom:0;word-break:normal}html body pre code,html body pre tt{display:inline;max-width:initial;padding:0;margin:0;overflow:initial;line-height:inherit;word-wrap:normal;background-color:transparent;border:0}html body pre code:after,html body pre code:before,html body pre tt:after,html body pre tt:before{content:normal}html body blockquote,html body dl,html body ol,html body p,html body pre,html body ul{margin-top:0;margin-bottom:16px}html body kbd{color:#000;border:1px solid #d6d6d6;border-bottom:2px solid #c7c7c7;padding:2px 4px;background-color:#f0f0f0;border-radius:3px}@media print{html body{background-color:#fff}html body h1,html body h2,html body h3,html body h4,html body h5,html body h6{color:#000;page-break-after:avoid}html body blockquote{color:#5c5c5c}html body pre{page-break-inside:avoid}html body table{display:table}html body img{display:block;max-width:100%;max-height:100%}html body code,html body pre{word-wrap:break-word;white-space:pre}}.markdown-preview{width:100%;height:100%;box-sizing:border-box}.markdown-preview ul{list-style:disc}.markdown-preview ul ul{list-style:circle}.markdown-preview ul ul ul{list-style:square}.markdown-preview ol{list-style:decimal}.markdown-preview ol ol,.markdown-preview ul ol{list-style-type:lower-roman}.markdown-preview ol ol ol,.markdown-preview ol ul ol,.markdown-preview ul ol ol,.markdown-preview ul ul ol{list-style-type:lower-alpha}.markdown-preview .newpage,.markdown-preview .pagebreak{page-break-before:always}.markdown-preview pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber}.markdown-preview pre.line-numbers>code{position:relative}.markdown-preview pre.line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:1em;font-size:100%;left:0;width:3em;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}.markdown-preview pre.line-numbers .line-numbers-rows>span{pointer-events:none;display:block;counter-increment:linenumber}.markdown-preview pre.line-numbers .line-numbers-rows>span:before{content:counter(linenumber);color:#999;display:block;padding-right:.8em;text-align:right}.markdown-preview .mathjax-exps .MathJax_Display{text-align:center!important}.markdown-preview:not([data-for=preview]) .code-chunk .code-chunk-btn-group{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .status{display:none}.markdown-preview:not([data-for=preview]) .code-chunk .output-div{margin-bottom:16px}.markdown-preview .md-toc{padding:0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link div,.markdown-preview .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}.markdown-preview .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}.scrollbar-style::-webkit-scrollbar{width:8px}.scrollbar-style::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}.scrollbar-style::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode]){position:relative;width:100%;height:100%;top:0;left:0;margin:0;padding:0;overflow:auto}html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{position:relative;top:0;min-height:100vh}@media screen and (min-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em calc(50% - 457px + 2em)}}@media screen and (max-width:914px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode]) .markdown-preview{font-size:14px!important;padding:1em}}@media print{html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{display:none}}html body[for=html-export]:not([data-presentation-mode]) #sidebar-toc-btn{position:fixed;bottom:8px;left:8px;font-size:28px;cursor:pointer;color:inherit;z-index:99;width:32px;text-align:center;opacity:.4}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] #sidebar-toc-btn{opacity:1}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc{position:fixed;top:0;left:0;width:300px;height:100%;padding:32px 0 48px 0;font-size:14px;box-shadow:0 0 4px rgba(150,150,150,.33);box-sizing:border-box;overflow:auto;background-color:inherit}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar{width:8px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-track{border-radius:10px;background-color:transparent}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc::-webkit-scrollbar-thumb{border-radius:5px;background-color:rgba(150,150,150,.66);border:4px solid rgba(150,150,150,.66);background-clip:content-box}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc a{text-decoration:none}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc{padding:0 16px}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link{display:inline;padding:.25rem 0}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link div,html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper .md-toc-link p{display:inline}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .md-sidebar-toc .md-toc .md-toc-link-wrapper.highlighted .md-toc-link{font-weight:800}html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{left:300px;width:calc(100% - 300px);padding:2em calc(50% - 457px - 300px / 2);margin:0;box-sizing:border-box}@media screen and (max-width:1274px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{padding:2em}}@media screen and (max-width:450px){html body[for=html-export]:not([data-presentation-mode])[html-show-sidebar-toc] .markdown-preview{width:100%}}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .markdown-preview{left:50%;transform:translateX(-50%)}html body[for=html-export]:not([data-presentation-mode]):not([html-show-sidebar-toc]) .md-sidebar-toc{display:none}
/* Please visit the URL below for more information: */
/*   https://shd101wyy.github.io/markdown-preview-enhanced/#/customize-css */

      </style>
      <!-- The content below will be included at the end of the <head> element. --><script type="text/javascript">
  document.addEventListener("DOMContentLoaded", function () {
    // your code here
  });
</script></head><body for="html-export">
    
    
      <div class="crossnote markdown-preview  ">
      
<h2 id="marketing-tracking-of-craiglists-used-cars">Marketing Tracking of Craiglist's Used Cars </h2>
<h2 id="table-of-contents">Table of Contents </h2>
<ol>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#problem-definition">Problem Definition</a></li>
<li><a href="#data-collection">Data Collection</a></li>
<li><a href="#exploratory-data-analysis-eda">Exploratory Data Analysis (EDA)</a></li>
<li><a href="#data-preprocessing">Data Preprocessing</a></li>
<li><a href="#feature-engineering">Feature Engineering</a></li>
<li><a href="#modeling">Modeling</a></li>
<li><a href="#model-evaluation">Model Evaluation</a></li>
<li><a href="#conclusion-and-future-work">Conclusion and Future Work</a></li>
<li><a href="#references">References</a></li>
</ol>
<h2 id="introduction">Introduction </h2>
<p><strong>Growing up, I had a family friend who was always poring over Craigslist ads, buying cars, fixing them up, and flipping them for profit. Each flip took him at least forty hours of searching. I can still picture him, bathed in the dim glow of a cathode ray tube, surrounded by stacks of booklets.</strong></p>
<p>This project is an ode to that family friend. It aims to build a tool to predict Craigslist car prices—similar to the tools used by Kelley Blue Book and captive financial companies like Ford Financing. Our anonymous hero could use this tool to efficiently find underpriced offers and snatch them up before others do.</p>
<p>Taking it a step further, our hero could even create a synthetic dataset of a thousand representative vehicles, train the model month by month, and observe how the prices of your synthetic vehicles change over time. Knowing the test data was fixed, any changes in price are attributable to changes in the trained model. This could be used as an index providing valuable insights into market trends and movements.</p>
<h2 id="problem-definition">Problem Definition </h2>
<p>A generous contributor has scraped 450,000 car postings from Craigslist and shared them on <a href="https://www.kaggle.com/datasets/austinreese/craigslist-carstrucks-data/code">Kaggle</a>. I have downloaded the zipped CSV file, and this is where our analysis begins. The target variable is the price, represented in USD. The dataset includes eighteen useful covariates, such as a region, a metro area, price in USD, year, year of manufacture, manufacturer (e.g., Ram or Jeep), model (e.g., Silverado or Forester), condition (e.g., good or fair), cylinders (e.g., 4 or 6), fuel (e.g., diesel or gas), odometer (miles traveled), title status (e.g., rebuilt or clean), transmission (e.g., automatic or manual), drive (e.g., FWD or RWD), type (e.g., sedan or truck), paint color (e.g., white or black), state (e.g., Wisconsin), and lat(itude) and long(itude) (representing geographical location).</p>
<h2 id="exploratory-data-analysis-eda">Exploratory Data Analysis (EDA) </h2>
<h3 id="1-data-overview">1. Data Overview </h3>
<p>For a thorough EDA using <code>y_data_profiling</code>, see the visualizations from <a href="results/data_profile_cleaned_subsampled_to_one_percent">pre_proccessing</a> and <a href="results/data_profile_raw_subsampled_to_one_percent">post processing</a>. In the interest of space, I will mention the most pertinent details. The price variable is heavily right-skewed, as is the odometer reading, which contains some incredible values of 10 million or more—equivalent to twenty round trips to the moon. It’s safe to say there are some data quality issues, which we will address in <a href="#data-preprocessing">data preprocessing</a>. Another pertinent topic is the high frequency of Carvana ads at XYZ%; since they exhibit higher data quality and more consistency across ads, they form an interesting part of the puzzle. However, their descriptions are mostly identicial boilerplate across many ads.</p>
<p>Digging into interactions below, we see a three-way interaction among price, age, and odometer reading. Older vehicles typically have more miles and are worth less; untangling mileage from age is a complex problem that is be beyond the scope of this paper. We also notice interactions between (word frequnecy)[#feature-engineering] and odometer readings, suggesting that certain words are used more or less frequently depending on car mileage; this aligns with expectations. No one describes their brand new sports car as "reliable"; that term of endearment is typically reserved for the family workhorse van that has been picking up groceries for a decade or more. Note, for clarity sake, the plot below only shows a few of the many, many tf_idf word columns.</p>
<p>Finally, the manufacturer shows a correlation with both the number of cylinders and transmission type, which again conforms to common sense. Additionally, about eleven percent of the rows appear to be exact duplicates. While they could represent truly different cars, the exact matching of price, odometer, color, etc., strains credibility, so we will drop these results. Likely people are reposting the same ad to make their ad appear new.</p>
<p>PROBLEM: ADD num words as variable</p>
<h3 id="2-data-visualization">2. Data Visualization </h3>
<ul>
<li>Histograms of numerical features (e.g., price distribution)</li>
<li>Scatter plots (e.g., price vs. mileage, price vs. year)</li>
<li>Correlation heatmaps to show relationships between features</li>
</ul>
<h2 id="data-preprocessing-and-feature-engineering">Data Preprocessing and Feature Engineering </h2>
<h3 id="1-handling-missing-values">1. Handling Missing Values </h3>
<p>Missing price or Odometer readings were removed; they are too crucial to try to impute. Missing values were imputed only for the linear regression approach and the method of imputation was just a standard mean or mode. A brief tour into missing values is in order. All columns are likely a mix Missing Not at Random and Missing at Random. Missing descriptions are probably missing because it would be hard to give a good description of a bad car. A rusted, sun beaten car missing a paint color is missing at random becuase the missingness is really tied to the condition of the car, not the paint color itself. This missingness should cast a bit of doubt on any results from linear regression.</p>
<h3 id="2-filtering-data">2 Filtering Data </h3>
<p>Craigslist seems especially prone to messy data for two reasons; individual posters are not professionals with a corporate image, hiding info is generally advantagous and most importantly price anchoring. Good cars worth a lot are generally owned by more interenet savy people, and spending the time to set up a great ad to gain 2% price is worth more on a more expensive car. Bad stuff is best left unmentioned and then discussed later if asked about.</p>
<p>The other key problem is <a href="https://en.wikipedia.org/wiki/Anchoring_effect">price anchoring</a>. The highest a buyer will sell his car for is the first price they mention. Much better to let the buyer offer a price and then ask for more regardless. By not listing a price or listing for silly valuse like <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn><mi>m</mi><mi>i</mi><mi>l</mi><mi>l</mi><mi>i</mi><mi>o</mi><mi>n</mi><mi>o</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">9 million or</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em;"></span><span class="mord">9</span><span class="mord mathnormal">mi</span><span class="mord mathnormal" style="margin-right:0.01968em;">ll</span><span class="mord mathnormal">i</span><span class="mord mathnormal">o</span><span class="mord mathnormal">n</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span></span></span></span>1, they can avoid anchor their price.</p>
<p>With this in mind, I applied several filters. I removed any cars less then <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2000</mn><mi>a</mi><mi>s</mi><mi>t</mi><mi>h</mi><mi>e</mi><mi>s</mi><mi>e</mi><mi>w</mi><mi>e</mi><mi>r</mi><mi>e</mi><mi>s</mi><mi>c</mi><mi>r</mi><mi>a</mi><mi>p</mi><mi mathvariant="normal">/</mi><mi>p</mi><mi>a</mi><mi>r</mi><mi>t</mi><mi>s</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>s</mi><mi>o</mi><mi>r</mi><mi>p</mi><mi>r</mi><mi>i</mi><mi>c</mi><mi>e</mi><mi>a</mi><mi>n</mi><mi>c</mi><mi>h</mi><mi>o</mi><mi>r</mi><mi>i</mi><mi>n</mi><mi>g</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>n</mi><mi>y</mi><mi>c</mi><mi>a</mi><mi>r</mi><mi>s</mi><mi>o</mi><mi>v</mi><mi>e</mi><mi>r</mi></mrow><annotation encoding="application/x-tex">2000 as these were scrap/parts cars or price anchoring and any cars over</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">2000</span><span class="mord mathnormal">a</span><span class="mord mathnormal">s</span><span class="mord mathnormal">t</span><span class="mord mathnormal">h</span><span class="mord mathnormal">ese</span><span class="mord mathnormal" style="margin-right:0.02691em;">w</span><span class="mord mathnormal" style="margin-right:0.02778em;">erescr</span><span class="mord mathnormal">a</span><span class="mord mathnormal">p</span><span class="mord">/</span><span class="mord mathnormal">p</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">t</span><span class="mord mathnormal">sc</span><span class="mord mathnormal">a</span><span class="mord mathnormal" style="margin-right:0.02778em;">rsor</span><span class="mord mathnormal">p</span><span class="mord mathnormal" style="margin-right:0.02778em;">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal">ce</span><span class="mord mathnormal">an</span><span class="mord mathnormal">c</span><span class="mord mathnormal">h</span><span class="mord mathnormal" style="margin-right:0.02778em;">or</span><span class="mord mathnormal">in</span><span class="mord mathnormal" style="margin-right:0.03588em;">g</span><span class="mord mathnormal">an</span><span class="mord mathnormal">d</span><span class="mord mathnormal">an</span><span class="mord mathnormal">yc</span><span class="mord mathnormal">a</span><span class="mord mathnormal">rso</span><span class="mord mathnormal" style="margin-right:0.03588em;">v</span><span class="mord mathnormal" style="margin-right:0.02778em;">er</span></span></span></span>125,000. With luxury used car markets online, most of the ads i found above $125,000 seemed illegitmate. Finally, I removed any cars over 300,000 miles. That is a reasonable upper bound for a cars lifespand and most of the ones above it were price anchoring/creating silly values to hide bad info. Lastly, I removed all duplicate rows removing about eleven percent of the data.</p>
<h3 id="2-feature-engineering">2. Feature Engineering </h3>
<p>This mainly took two parts. The first is more standard feature engineering. I created flags for if the ad had a description and if the ad was a carvana ad. I also took condition and converted from categorical to ordinal. Excellent, fair and poor have an obvious order and that information should be retained. Similairly, number of cylidners was converted from a string to a number to retain that ordinal info.</p>
<p>The more interesting peice of feature engineering was analyzing the description text. A lot of text analysis centers on classification and sentiment analysis.A first apporach was a bag of words style approach but I pivoted to <a href="https://builtin.com/articles/tf-idf">term frequency, inverse document frequency</a>. To make a long story short, words that appear in fewer descriptions are weighted more heavily (IDF), while words that are show up alot in a specific document are weighted more heavily. In the end, you affix a column of words and how their score for each individual row, ie, description. We can then use these as variables later in the modeling.</p>
<h3 id="4-splitting-the-dataset">4. Splitting the Dataset </h3>
<p>I choose a train, valid, test split of 75/20/5.</p>
<h2 id="modeling">Modeling </h2>
<table>
<thead>
<tr>
<th>Model</th>
<th>Explanatory Variables</th>
<th>Hyper Parameters</th>
<th>RMSE</th>
<th>R²</th>
</tr>
</thead>
<tbody>
<tr>
<td>Ordinary Least Squares</td>
<td>odometer</td>
<td><code>None</code></td>
<td>$12110</td>
<td>29.2%</td>
</tr>
<tr>
<td>Log Least Squares</td>
<td>year, manufacturer, odometer, paint_color, state, title_status</td>
<td><code>None</code></td>
<td>$10,986</td>
<td>41.8%</td>
</tr>
<tr>
<td>LightGBM</td>
<td>all standard variables</td>
<td><code>{'learning_rate': 0.01, 'max_depth': 6,'boosting_type': "gbdt"</code></td>
<td>$6180</td>
<td>81.7%</td>
</tr>
<tr>
<td>LightGBM with HyperOpt and Text</td>
<td>all standard variables, has_description?, is_carvana_ad?, 500 words (TF_IDF)</td>
<td><code>{'learning_rate': 0.05, 'max_depth': 8,'boosting_type': "gbdt",'number_of_leaves':166,'min_data_in_leaf': 5000}</code></td>
<td>$4998</td>
<td>88%</td>
</tr>
</tbody>
</table>
<p><em>Table 1</em> The four modeling approaches</p>
<h3 id="1-simple-ordinary-least-squares">1. Simple Ordinary Least Squares </h3>
<p>I iterated through four models in this project progressively improving. To asses model quality, I will use RMSE, and R^2 while also favoring simpler models with equivalent succes.  My first model was the first stop on almost any good regression data science project, linear regression. My  baseline was oridanry least squares regression with Odometer as my covariate. The good news is that model trains incredibly quickly and it is the most interptable of all models. I got a final RMSE of <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>12</mn><mi>k</mi><mi>a</mi><mi>n</mi><mi>d</mi><mi>a</mi><mi>n</mi><msup><mi>R</mi><mn>2</mn></msup><mi>o</mi><mi>f</mi><mn>29</mn></mrow><annotation encoding="application/x-tex">12k and an R^2 of 29%. So the models off by about 12,000 dollars on average; this isn't good enough for our use case. While the model, odometer, explains about 29% of the total variation in price. The models extreme interptablity is also nice; any car's value starts at</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0085em;vertical-align:-0.1944em;"></span><span class="mord">12</span><span class="mord mathnormal">kan</span><span class="mord mathnormal">d</span><span class="mord mathnormal">an</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.00773em;">R</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord mathnormal">o</span><span class="mord mathnormal" style="margin-right:0.10764em;">f</span><span class="mord">29</span></span></span></span>31,140 and every consectutive mile reduces value by 12.75 cents. In the interest of brevity, I won't dive too deeply into checking the assumptions because they all fail: linearity, homoskedascity, normality, all fail. While many types of inference are robust, this is too much for even the most robust linear regression infrences. So left with an uninterptable and innaccurate model, its time to go back to the drawing board. Another problem is the negative predictions; after 250,000 miles, the model starts predicting negative prices.</p>
<div style="display: flex; gap: 40px;">
    <img src="results/Simple Linear Regression of Price by Odometer/residuals.png" alt="Image 1">
    <img src="results/Simple Linear Regression of Price by Odometer/ols_results.png" alt="Image 2">
</div>
_*Figure 1*_ Results of the simple least squares regression, note how many predictions are actually negative.  
<h3 id="2-log-multiple-least-squares">2. Log Multiple Least Squares </h3>
<p>In my next model, I wanted to tackle two problems; many negative price predictions and decrease bias at the cost of increasing variance. To do this, I started by logging price. The intuition behind this is that it price spans several magnitudes and predicting the log will never be negative. The second prong, dealing with an underfitting model, was achieved by introducing a few extra terms to the model: year, manufacturer, state, title_status and paint_color. I selected these variables because they had low cardinality, lived experience/common sense and low rates of missing values. Variables with a lot of missing values would require a lot of mean/mode imputation reducing the value of the variable. Variables with high cardinality reduce model interptablity and risk dicing up data too thinly.</p>
<p>Checking the results below, the negative predictions have dissappeared and we are seeing an improvement in model accuracy, with about 40% of the variability in price explained by our model. In addition, we are on average off by about <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mi>k</mi><mi>l</mi><mi>e</mi><mi>s</mi><mi>s</mi><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">1k less,</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em;"></span><span class="mord">1</span><span class="mord mathnormal" style="margin-right:0.03148em;">k</span><span class="mord mathnormal" style="margin-right:0.01968em;">l</span><span class="mord mathnormal">ess</span><span class="mpunct">,</span></span></span></span>11k. While thats a great step in the right direction of accuracy, we now have 80 seperate terms in the function. In addition, we now have correlated covariates that are skewing our beta coefficents and very strange results such as cars in West Virginia being more expensive then New York.</p>
<div style="display: flex; gap: 40px;">
    <img src="results/Log price Linear Regression/residuals.png" alt="Image 1">
    <img src="results/Log price Linear Regression/Log_mls_results.png" alt="Image 2">
</div>
_*Figure 12*_ Results of the log mulitiple least squares regression, note I cut off many rows in the results for brevity. Full results can be found in GH. 
<h3 id="3light-gbm">3.Light GBM </h3>
<p>Linear regression isn't going to cut it on this data set so I'll try another tool, Light GBM. Let's try a naive approach first, using all of our useable varialbes and leaving out any words or feature engineered variables or hyper parameter tuning. Consider it more of a base line approach. The great news is it provided a dramatic improvement in our model preformance.  Our RMSE dropped down to $6,200 and our model is able to explain about 82% of the variation in price. This a dramatic improvement in accuracy but costed us a bit of speed and explainability. Specifically the model went from about 10 seconds to fit model two mentioned above, to about four minutes to fit model three. As this is a model that would likey be trained once a week at most, this is a fine trade off to me.</p>
<p>Addressing interptability is a bit harder, but for this, I will use <a href="https://shap.readthedocs.io/en/latest/index.html">SHAP</a> to better understand how specific variable affect the predictions. The SHAP summary plot below is bit daunting at first. But looking ath the first row, year, the farther right you go, the higher SHAP value, increasing the predicted price. Looking at the color, most of the right most values are red, which are high feature values. This should make sense, higher manufacturing years are newer and are going to sell for more. Odometer has a similiar but exactly opposite story for obvious reasons. Interestingly, longitude, at the lowest values (light blue), are actually associated with positive increases in price (high SHAP values). Why? Well, the west coast, Alaska and Hawaii have the lowest longitude, these are high cost of living places and this is what I think we are seeing! The far right skew in region tells a similar story I believe. However, I havent been able to (yet) figure out what these exact values are, I suspect they are high cost of living locations. Simiarly, title statue for the most part, has no effect on the value, but the occasional value severeally decreases the price. This conforms to our EDA where most titles were clean but some were salvage, parts, or lein, any of which is going to impede a high sales price.</p>
<div style="display: flex; gap: 40px;">
    <img src="results\light_gbm_basic/shap_summary_plot.png" alt="Image 1">
    <img src="results\light_gbm_basic\rmse_over_rounds.png" alt="Image 2">
</div>
<h3 id="4-light-gbm-with-hyperopt-and-words">4. Light GBM with HyperOpt and Words </h3>
<p>From here, there is a kaledoscope of options to try next: hyper parameter tuning, add it text data from the description, utilize lat and long to pull in zip code data, implementing crossvalidation, explore the time and date of posting.</p>
<p>The first stop was addressing overfit and while here, I might as well set up HyperOpt. HyperOpt is one of my favorite tools for hyperparameter optimization. It uses a Bayesian framework to more efficeintly search using prior runs to inform future runs. An analogy, You are looking for a plane that flew between New York and London and crashed in the ocean. If you find debries, you should bring all your searchers in to that one spot and really comb that location.</p>
<p>There are three main hyperparemeters I tried to optimize; learning rate, max depth, number of TF_IDF words and L1, L2 regularization. We are not tuning on number of leaves.I have fixed that to be 65% of 2^max_depth. <a href="https://lightgbm.readthedocs.io/en/latest/Parameters-Tuning.html">Why?</a>. Because Light GBM grows leaf first, not level first. By fitting max depth and setting leaves to be equal to it, you just back yourself in a level first methodology ala random forest. This is okay if you don't have over fit, but we do, so were doing it like this instead.</p>
<p>Number of TF_IDF was always selected to be max at 500, so the existing code doesn't show this as checking this was wasting compute. Trying both L1 and L2 regualarization at the same time is inspired by ElasticNet; this idea was inspired by <a href="https://datascience.stackexchange.com/questions/57255/l1-l2-regularization-in-light-gbm">StackExchange</a>.</p>
<p>Interpting TF_IDF, TO DO DEVIN</p>
<div style="display: flex; gap: 40px;">
    <img src="results/light_gbm__hyperopt_and_feature_engineering/shap_summary_plot.png" alt="Image 1">
    <img src="results\light_gbm__HyperOpt_and_feature_engineering\rmse_over_rounds.png" alt="Image 2">
</div>
<p>FIX UP ALT image titles</p>
<h3 id="compare-the-given-models">Compare the given models. </h3>
<p>Comparing the models, Linear regression should offer interptability and statistical infrence. But without any of the assumptions holding and high correlation, that doesn't really hold. As such, I think Light GBM is just a better model for this use case. The next questions becomes, do you want to use the model with TF_IDF and feature engineering or the base model. The more complex model, four, is about five times slower to train. But in my envisioned use case, it only trains at most once a week. So model training speed isn't super important. Prediction speed is perhaps a bit more important as you want to be scraping data, and predicting on the data daily if not hourly so you can know about the deals asap!</p>
<p>I think the ideal end case is using model four and using a model in combination with SHAP to create a waterfall plot and see how and why the lightGBM model is adjusting the price how it is. From there, you can use subject matter expertise, to agree with, tweak or ignore each prediction. Heres an example from the model we trained.  TO DO DEVIN FILL IN T</p>
<h2 id="conclusion-and-future-work">Conclusion and Future Work </h2>
<p>In conclusion, we found a featured engineered model with text in Light GBM to be the best model. We were able to get an RMSE OF XYZ and epxlaine about UFUF% of the variance in price. The most important variables were odometer, region and year along with word XSSS,SSSD,KKKD,DDDD, TO DO DEVIN. THis current approach has limitiations, it is limited to the time frame the data was scraped (early 2024) and we cut about 15% of the totals rows due to impossible odometers and prices. These were corrupt at random and its hard to say how this changes the model and our depiction of it. Finally, Carvana is a bit player in the market, but given how fractured the craigslist market it, they are by far the ]biggest player. They very well might set the market and more fcuse should be given to their pricign.</p>
<h2 id="future-work">Future work </h2>
<p>Pull out useful info from  craigslist carvana ad's. Today there is too much static data in the descriptions that overwhelems TF_IDF, so I turn carvana ad's into a boolean varialbe. A further analysis could just delete the boiler plate and extract the nuggets.</p>
<p>Find and utilzie the images. The current data only points to image URLs; I could go an download all these images and then utilize them. Thats beyond the scope of this project today. But from here, you could build a CVML model to detect car quality. Specifically looking for things like rust, dents, and scratches. I know this is possible and have worekd on it before but can't share more without spilling the secret sauce.</p>

      </div>
      
      
    
    
    
    
    
    
  
    </body></html>